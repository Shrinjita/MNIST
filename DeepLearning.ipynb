{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNLAXoCZaY8o2+3YONe+gHB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shrinjita/MNIST/blob/main/DeepLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EXPERIMENT 2**"
      ],
      "metadata": {
        "id": "tV6IktiD_tlJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJd1UIwRxxBW",
        "outputId": "6ddc7d30-3ba4-4835-9137-72189ad239ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Sample dataset\n",
        "data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/deep learning/weather_forecast.csv')\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Vectorize the text data\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(df['Outlook'] + ' ' + df['Temperature'] + ' ' + df['Humidity'] + ' ' + df['Windy'])\n",
        "y = df['Play'].apply(lambda x: 1 if x == 'yes' else 0)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train = X[:13]\n",
        "X_test = X[13:]\n",
        "y_train = y[:13]\n",
        "y_test = y[13:]\n",
        "\n",
        "# Train the Naive Bayes classifier\n",
        "nb = MultinomialNB()\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = nb.predict(X_test)\n",
        "\n",
        "# Print the results\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Custom prediction\n",
        "custom_test = vectorizer.transform(['overcast mild high weak'])\n",
        "custom_prediction = nb.predict(custom_test)\n",
        "print(\"Prediction for Outlook=overcast, Temperature=mild, Humidity=high, Windy=weak:\", 'yes' if custom_prediction[0] == 1 else 'no')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwgnbvpnyIbE",
        "outputId": "667e522e-6cad-44b8-f8ea-7097511cba55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Confusion Matrix:\n",
            " [[1]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         1\n",
            "   macro avg       1.00      1.00      1.00         1\n",
            "weighted avg       1.00      1.00      1.00         1\n",
            "\n",
            "Prediction for Outlook=overcast, Temperature=mild, Humidity=high, Windy=weak: no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EXPERIMENT 3**"
      ],
      "metadata": {
        "id": "fFOj17S-AEiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1- Import Data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "dib = pd.read_csv('/content/drive/My Drive/Colab Notebooks/deep learning/diabetes.csv')  # Import data\n",
        "print(dib.shape)  # Understand shape of the dataframe\n",
        "dib.head()  # Look at few rows"
      ],
      "metadata": {
        "id": "WhlqCskT4NsQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "12ffb9f7-2dea-4c54-dca8-a789439562a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(768, 9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.627   50        1  \n",
              "1                     0.351   31        0  \n",
              "2                     0.672   32        1  \n",
              "3                     0.167   21        0  \n",
              "4                     2.288   33        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e4e354ee-da83-4cb7-934e-9c08fe6468bf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4e354ee-da83-4cb7-934e-9c08fe6468bf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e4e354ee-da83-4cb7-934e-9c08fe6468bf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e4e354ee-da83-4cb7-934e-9c08fe6468bf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5731f241-5dc7-491d-b42a-2f2aa2f0a853\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5731f241-5dc7-491d-b42a-2f2aa2f0a853')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5731f241-5dc7-491d-b42a-2f2aa2f0a853 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dib",
              "summary": "{\n  \"name\": \"dib\",\n  \"rows\": 768,\n  \"fields\": [\n    {\n      \"column\": \"Pregnancies\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 17,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          6,\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Glucose\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31,\n        \"min\": 0,\n        \"max\": 199,\n        \"num_unique_values\": 136,\n        \"samples\": [\n          151,\n          101,\n          112\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BloodPressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19,\n        \"min\": 0,\n        \"max\": 122,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          86,\n          46,\n          85\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SkinThickness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 0,\n        \"max\": 99,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          7,\n          12,\n          48\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Insulin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 115,\n        \"min\": 0,\n        \"max\": 846,\n        \"num_unique_values\": 186,\n        \"samples\": [\n          52,\n          41,\n          183\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BMI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.884160320375446,\n        \"min\": 0.0,\n        \"max\": 67.1,\n        \"num_unique_values\": 248,\n        \"samples\": [\n          19.9,\n          31.0,\n          38.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DiabetesPedigreeFunction\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3313285950127749,\n        \"min\": 0.078,\n        \"max\": 2.42,\n        \"num_unique_values\": 517,\n        \"samples\": [\n          1.731,\n          0.426,\n          0.138\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 21,\n        \"max\": 81,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          60,\n          47,\n          72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Outcome\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check columns\n",
        "print(dib.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxPdF8778um7",
        "outputId": "f86e68b1-741b-4f2b-a3f0-ceb960ea352d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
            "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Feature Engineering\n",
        "X = dib[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']]  # Feature variables\n",
        "y = dib['Outcome']  # Response variable"
      ],
      "metadata": {
        "id": "0Q_nr8CG9Dlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Split data into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=100)"
      ],
      "metadata": {
        "id": "hU5Z0rSA-Jj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Build a binary classification model\n",
        "import statsmodels.api as sm\n",
        "\n",
        "X_train_sm = sm.add_constant(X_train)\n",
        "logm2 = sm.GLM(y_train, X_train_sm, family=sm.families.Binomial())\n",
        "res = logm2.fit()\n",
        "res.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "5AhZRsUt-ety",
        "outputId": "62c5e8c6-5be8-41fc-d0ae-bf0b65534648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                 Generalized Linear Model Regression Results                  \n",
              "==============================================================================\n",
              "Dep. Variable:                Outcome   No. Observations:                  537\n",
              "Model:                            GLM   Df Residuals:                      528\n",
              "Model Family:                Binomial   Df Model:                            8\n",
              "Link Function:                  Logit   Scale:                          1.0000\n",
              "Method:                          IRLS   Log-Likelihood:                -245.19\n",
              "Date:                Wed, 31 Jul 2024   Deviance:                       490.37\n",
              "Time:                        08:50:35   Pearson chi2:                     667.\n",
              "No. Iterations:                     5   Pseudo R-squ. (CS):             0.3158\n",
              "Covariance Type:            nonrobust                                         \n",
              "============================================================================================\n",
              "                               coef    std err          z      P>|z|      [0.025      0.975]\n",
              "--------------------------------------------------------------------------------------------\n",
              "const                       -9.3762      0.908    -10.328      0.000     -11.155      -7.597\n",
              "Pregnancies                  0.1084      0.039      2.803      0.005       0.033       0.184\n",
              "Glucose                      0.0373      0.005      7.973      0.000       0.028       0.046\n",
              "BloodPressure               -0.0096      0.006     -1.566      0.117      -0.022       0.002\n",
              "SkinThickness               -0.0004      0.008     -0.048      0.962      -0.017       0.016\n",
              "Insulin                     -0.0012      0.001     -1.103      0.270      -0.003       0.001\n",
              "BMI                          0.0952      0.018      5.197      0.000       0.059       0.131\n",
              "DiabetesPedigreeFunction     1.3783      0.367      3.758      0.000       0.659       2.097\n",
              "Age                          0.0202      0.011      1.809      0.070      -0.002       0.042\n",
              "============================================================================================\n",
              "\"\"\""
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Generalized Linear Model Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>        <td>Outcome</td>     <th>  No. Observations:  </th>  <td>   537</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>   528</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>     8</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Link Function:</th>         <td>Logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -245.19</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>            <td>Wed, 31 Jul 2024</td> <th>  Deviance:          </th> <td>  490.37</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                <td>08:50:35</td>     <th>  Pearson chi2:      </th>  <td>  667.</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Iterations:</th>          <td>5</td>        <th>  Pseudo R-squ. (CS):</th>  <td>0.3158</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "              <td></td>                <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th>                    <td>   -9.3762</td> <td>    0.908</td> <td>  -10.328</td> <td> 0.000</td> <td>  -11.155</td> <td>   -7.597</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Pregnancies</th>              <td>    0.1084</td> <td>    0.039</td> <td>    2.803</td> <td> 0.005</td> <td>    0.033</td> <td>    0.184</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Glucose</th>                  <td>    0.0373</td> <td>    0.005</td> <td>    7.973</td> <td> 0.000</td> <td>    0.028</td> <td>    0.046</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>BloodPressure</th>            <td>   -0.0096</td> <td>    0.006</td> <td>   -1.566</td> <td> 0.117</td> <td>   -0.022</td> <td>    0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>SkinThickness</th>            <td>   -0.0004</td> <td>    0.008</td> <td>   -0.048</td> <td> 0.962</td> <td>   -0.017</td> <td>    0.016</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Insulin</th>                  <td>   -0.0012</td> <td>    0.001</td> <td>   -1.103</td> <td> 0.270</td> <td>   -0.003</td> <td>    0.001</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>BMI</th>                      <td>    0.0952</td> <td>    0.018</td> <td>    5.197</td> <td> 0.000</td> <td>    0.059</td> <td>    0.131</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>DiabetesPedigreeFunction</th> <td>    1.3783</td> <td>    0.367</td> <td>    3.758</td> <td> 0.000</td> <td>    0.659</td> <td>    2.097</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Age</th>                      <td>    0.0202</td> <td>    0.011</td> <td>    1.809</td> <td> 0.070</td> <td>   -0.002</td> <td>    0.042</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}           &     Outcome      & \\textbf{  No. Observations:  } &      537    \\\\\n\\textbf{Model:}                   &       GLM        & \\textbf{  Df Residuals:      } &      528    \\\\\n\\textbf{Model Family:}            &     Binomial     & \\textbf{  Df Model:          } &        8    \\\\\n\\textbf{Link Function:}           &      Logit       & \\textbf{  Scale:             } &    1.0000   \\\\\n\\textbf{Method:}                  &       IRLS       & \\textbf{  Log-Likelihood:    } &   -245.19   \\\\\n\\textbf{Date:}                    & Wed, 31 Jul 2024 & \\textbf{  Deviance:          } &    490.37   \\\\\n\\textbf{Time:}                    &     08:50:35     & \\textbf{  Pearson chi2:      } &     667.    \\\\\n\\textbf{No. Iterations:}          &        5         & \\textbf{  Pseudo R-squ. (CS):} &   0.3158    \\\\\n\\textbf{Covariance Type:}         &    nonrobust     & \\textbf{                     } &             \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n                                  & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{const}                    &      -9.3762  &        0.908     &   -10.328  &         0.000        &      -11.155    &       -7.597     \\\\\n\\textbf{Pregnancies}              &       0.1084  &        0.039     &     2.803  &         0.005        &        0.033    &        0.184     \\\\\n\\textbf{Glucose}                  &       0.0373  &        0.005     &     7.973  &         0.000        &        0.028    &        0.046     \\\\\n\\textbf{BloodPressure}            &      -0.0096  &        0.006     &    -1.566  &         0.117        &       -0.022    &        0.002     \\\\\n\\textbf{SkinThickness}            &      -0.0004  &        0.008     &    -0.048  &         0.962        &       -0.017    &        0.016     \\\\\n\\textbf{Insulin}                  &      -0.0012  &        0.001     &    -1.103  &         0.270        &       -0.003    &        0.001     \\\\\n\\textbf{BMI}                      &       0.0952  &        0.018     &     5.197  &         0.000        &        0.059    &        0.131     \\\\\n\\textbf{DiabetesPedigreeFunction} &       1.3783  &        0.367     &     3.758  &         0.000        &        0.659    &        2.097     \\\\\n\\textbf{Age}                      &       0.0202  &        0.011     &     1.809  &         0.070        &       -0.002    &        0.042     \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{Generalized Linear Model Regression Results}\n\\end{center}"
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = res.predict(X_train_sm)  # Predict diabetes"
      ],
      "metadata": {
        "id": "B8QF07OT_BIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Predict Diabetes\n",
        "# Create a new dataframe named dib_train which will include original and predicted diabetes\n",
        "data = {col: X_train[col] for col in X_train.columns}\n",
        "data['Diabetes'] = y_train\n",
        "data['y_train_pred'] = y_train_pred\n",
        "dib_train = pd.DataFrame(data)\n",
        "\n",
        "# Create predicted diabetes based on a 0.5 cut-off probability\n",
        "dib_train['Diabetes_predicted'] = dib_train.y_train_pred.map(lambda x: 1 if x > 0.5 else 0)\n",
        "dib_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iYDfRTQ5-jql",
        "outputId": "af8be9c9-eff5-4af7-d90b-b5c5953a75d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "155            7      152             88             44        0  50.0   \n",
              "150            1      136             74             50      204  37.4   \n",
              "78             0      131              0              0        0  43.2   \n",
              "9              8      125             96              0        0   0.0   \n",
              "142            2      108             52             26       63  32.5   \n",
              "\n",
              "     DiabetesPedigreeFunction  Age  Diabetes  y_train_pred  Diabetes_predicted  \n",
              "155                     0.337   36         1      0.894943                   1  \n",
              "150                     0.399   24         0      0.360796                   0  \n",
              "78                      0.270   26         1      0.627636                   1  \n",
              "9                       0.232   54         1      0.033715                   0  \n",
              "142                     0.318   22         0      0.149560                   0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-13b22798-a5c8-43d9-8fcf-b78dca3e7958\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Diabetes</th>\n",
              "      <th>y_train_pred</th>\n",
              "      <th>Diabetes_predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>7</td>\n",
              "      <td>152</td>\n",
              "      <td>88</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.337</td>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>0.894943</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>1</td>\n",
              "      <td>136</td>\n",
              "      <td>74</td>\n",
              "      <td>50</td>\n",
              "      <td>204</td>\n",
              "      <td>37.4</td>\n",
              "      <td>0.399</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0.360796</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>0</td>\n",
              "      <td>131</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>43.2</td>\n",
              "      <td>0.270</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "      <td>0.627636</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8</td>\n",
              "      <td>125</td>\n",
              "      <td>96</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.232</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "      <td>0.033715</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>2</td>\n",
              "      <td>108</td>\n",
              "      <td>52</td>\n",
              "      <td>26</td>\n",
              "      <td>63</td>\n",
              "      <td>32.5</td>\n",
              "      <td>0.318</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>0.149560</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13b22798-a5c8-43d9-8fcf-b78dca3e7958')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-13b22798-a5c8-43d9-8fcf-b78dca3e7958 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-13b22798-a5c8-43d9-8fcf-b78dca3e7958');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d23f8e4c-4029-4362-b665-fafd2781ab44\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d23f8e4c-4029-4362-b665-fafd2781ab44')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d23f8e4c-4029-4362-b665-fafd2781ab44 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dib_train",
              "summary": "{\n  \"name\": \"dib_train\",\n  \"rows\": 537,\n  \"fields\": [\n    {\n      \"column\": \"Pregnancies\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          7,\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Glucose\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32,\n        \"min\": 0,\n        \"max\": 199,\n        \"num_unique_values\": 129,\n        \"samples\": [\n          94,\n          154,\n          146\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BloodPressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19,\n        \"min\": 0,\n        \"max\": 114,\n        \"num_unique_values\": 44,\n        \"samples\": [\n          30,\n          114,\n          76\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SkinThickness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 0,\n        \"max\": 60,\n        \"num_unique_values\": 48,\n        \"samples\": [\n          13,\n          29,\n          38\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Insulin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 119,\n        \"min\": 0,\n        \"max\": 846,\n        \"num_unique_values\": 147,\n        \"samples\": [\n          250,\n          215,\n          128\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BMI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.019932673626172,\n        \"min\": 0.0,\n        \"max\": 67.1,\n        \"num_unique_values\": 217,\n        \"samples\": [\n          38.2,\n          19.3,\n          35.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DiabetesPedigreeFunction\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.33235369072096355,\n        \"min\": 0.078,\n        \"max\": 2.329,\n        \"num_unique_values\": 400,\n        \"samples\": [\n          0.482,\n          0.186,\n          0.19\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 21,\n        \"max\": 72,\n        \"num_unique_values\": 48,\n        \"samples\": [\n          39,\n          48,\n          56\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Diabetes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y_train_pred\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2805912899331964,\n        \"min\": 0.0011710895424717467,\n        \"max\": 0.984729562775199,\n        \"num_unique_values\": 537,\n        \"samples\": [\n          0.49212848364435413,\n          0.1269351150825147\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Diabetes_predicted\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Confusion Matrix and Accuracy\n",
        "from sklearn import metrics\n",
        "\n",
        "# Confusion matrix\n",
        "confusion = metrics.confusion_matrix(dib_train.Diabetes, dib_train.Diabetes_predicted)\n",
        "confusion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVoIlJto-tA7",
        "outputId": "03d4e127-fb6e-4106-8da5-04da9ff35251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[314,  36],\n",
              "       [ 74, 113]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Overall accuracy\n",
        "print(metrics.accuracy_score(dib_train.Diabetes, dib_train.Diabetes_predicted))"
      ],
      "metadata": {
        "id": "2H-ebckODrpN",
        "outputId": "0f99940d-8c83-4418-9e18-0a363ed5bac2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7951582867783985\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Variation with Cut-Off\n",
        "# Calculate Sensitivity, Specificity and accuracy with different probability cutoffs\n",
        "numbers = [float(x) / 10 for x in range(10)]\n",
        "\n",
        "for i in numbers:\n",
        "    dib_train[i] = dib_train.y_train_pred.map(lambda x: 1 if x > i else 0)\n",
        "dib_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "kaInw22H_TD3",
        "outputId": "1be4c8e8-57fb-43c5-adee-0605afed0ea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "155            7      152             88             44        0  50.0   \n",
              "150            1      136             74             50      204  37.4   \n",
              "78             0      131              0              0        0  43.2   \n",
              "9              8      125             96              0        0   0.0   \n",
              "142            2      108             52             26       63  32.5   \n",
              "\n",
              "     DiabetesPedigreeFunction  Age  Diabetes  y_train_pred  ...  0.0  0.1  \\\n",
              "155                     0.337   36         1      0.894943  ...    1    1   \n",
              "150                     0.399   24         0      0.360796  ...    1    1   \n",
              "78                      0.270   26         1      0.627636  ...    1    1   \n",
              "9                       0.232   54         1      0.033715  ...    1    0   \n",
              "142                     0.318   22         0      0.149560  ...    1    1   \n",
              "\n",
              "     0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  \n",
              "155    1    1    1    1    1    1    1    0  \n",
              "150    1    1    0    0    0    0    0    0  \n",
              "78     1    1    1    1    1    0    0    0  \n",
              "9      0    0    0    0    0    0    0    0  \n",
              "142    0    0    0    0    0    0    0    0  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bfd2a608-e71c-4521-883e-38b73745a791\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Diabetes</th>\n",
              "      <th>y_train_pred</th>\n",
              "      <th>...</th>\n",
              "      <th>0.0</th>\n",
              "      <th>0.1</th>\n",
              "      <th>0.2</th>\n",
              "      <th>0.3</th>\n",
              "      <th>0.4</th>\n",
              "      <th>0.5</th>\n",
              "      <th>0.6</th>\n",
              "      <th>0.7</th>\n",
              "      <th>0.8</th>\n",
              "      <th>0.9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>7</td>\n",
              "      <td>152</td>\n",
              "      <td>88</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.337</td>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>0.894943</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>1</td>\n",
              "      <td>136</td>\n",
              "      <td>74</td>\n",
              "      <td>50</td>\n",
              "      <td>204</td>\n",
              "      <td>37.4</td>\n",
              "      <td>0.399</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0.360796</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>0</td>\n",
              "      <td>131</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>43.2</td>\n",
              "      <td>0.270</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "      <td>0.627636</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8</td>\n",
              "      <td>125</td>\n",
              "      <td>96</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.232</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "      <td>0.033715</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>2</td>\n",
              "      <td>108</td>\n",
              "      <td>52</td>\n",
              "      <td>26</td>\n",
              "      <td>63</td>\n",
              "      <td>32.5</td>\n",
              "      <td>0.318</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "      <td>0.149560</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bfd2a608-e71c-4521-883e-38b73745a791')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bfd2a608-e71c-4521-883e-38b73745a791 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bfd2a608-e71c-4521-883e-38b73745a791');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-47d897ae-2d39-4a4a-8e90-d8ba4c9cc920\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-47d897ae-2d39-4a4a-8e90-d8ba4c9cc920')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-47d897ae-2d39-4a4a-8e90-d8ba4c9cc920 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dib_train"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "num = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "cutoff_df = pd.DataFrame(columns=['Probability', 'Accuracy', 'Sensitivity', 'Specificity'])\n",
        "\n",
        "for i in num:\n",
        "    cm1 = metrics.confusion_matrix(dib_train.Diabetes, dib_train[i])\n",
        "    total1 = sum(sum(cm1))\n",
        "    Accuracy = (cm1[0, 0] + cm1[1, 1]) / total1\n",
        "    Specificity = cm1[0, 0] / (cm1[0, 0] + cm1[0, 1])\n",
        "    Sensitivity = cm1[1, 1] / (cm1[1, 0] + cm1[1, 1])\n",
        "    cutoff_df.loc[i] = [i, Accuracy, Sensitivity, Specificity]\n",
        "# Plot accuracy, sensitivity, and specificity for various probabilities\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(cutoff_df['Probability'], cutoff_df['Accuracy'], label='Accuracy')\n",
        "plt.plot(cutoff_df['Probability'], cutoff_df['Sensitivity'], label='Sensitivity')\n",
        "plt.plot(cutoff_df['Probability'], cutoff_df['Specificity'], label='Specificity')\n",
        "plt.xlabel('Probability Cutoff')\n",
        "plt.ylabel('Metrics')\n",
        "plt.title('Metrics at Different Probability Cutoffs')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "kp6rP4Em_W2r",
        "outputId": "6c87a691-9ba6-4346-d6ce-c71865396889"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRYOUT 2"
      ],
      "metadata": {
        "id": "7vv3SpRqqtmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "iris=load_iris()\n",
        "X=iris.data\n",
        "Y=iris.target\n",
        "print(\"Size of Dataset {}\".format(len(X)))\n",
        "logreg=LogisticRegression()\n",
        "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.3,random_state=42)\n",
        "logreg.fit(x_train,y_train)\n",
        "predict=logreg.predict(x_test)\n",
        "print(\"Accuracy score on training set is {}\".format(accuracy_score(logreg.predict(x_train),y_train)))\n",
        "print(\"Accuracy score on test set is {}\".format(accuracy_score(predict,y_test)))"
      ],
      "metadata": {
        "id": "RQHXLlSA_m7X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca1af2ac-fb56-4cd2-d624-530973414078"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of Dataset 150\n",
            "Accuracy score on training set is 0.9619047619047619\n",
            "Accuracy score on test set is 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import cross_val_score,KFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "iris=load_iris()\n",
        "X=iris.data\n",
        "Y=iris.target\n",
        "logreg=LogisticRegression()\n",
        "kf=KFold(n_splits=5)\n",
        "score=cross_val_score(logreg,X,Y,cv=kf)\n",
        "print(\"Cross Validation Scores are {}\".format(score))\n",
        "print(\"Average Cross Validation score :{}\".format(score.mean()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8nW3WDDoYD2",
        "outputId": "028d1bf0-a63e-456f-9d91-5d541de31c02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross Validation Scores are [1.         1.         0.86666667 0.93333333 0.83333333]\n",
            "Average Cross Validation score :0.9266666666666665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import LeaveOneOut,cross_val_score\n",
        "iris=load_iris()\n",
        "X=iris.data\n",
        "Y=iris.target\n",
        "loo=LeaveOneOut()\n",
        "tree=RandomForestClassifier(n_estimators=10,max_depth=5,n_jobs=-1)\n",
        "score=cross_val_score(tree,X,Y,cv=loo)\n",
        "print(\"Cross Validation Scores are {}\".format(score))\n",
        "print(\"Average Cross Validation score :{}\".format(score.mean()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jthve22gpN2e",
        "outputId": "47d92bc8-34c0-446d-b5ec-95e4885678c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross Validation Scores are [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
            " 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1.]\n",
            "Average Cross Validation score :0.94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "Y = iris.target\n",
        "logreg = LogisticRegression(max_iter=200)\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "score = cross_val_score(logreg, X, Y, cv=skf)\n",
        "print(\"Cross Validation Scores are {}\".format(score))\n",
        "print(\"Average Cross Validation score: {}\".format(score.mean()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdUivnLPstI0",
        "outputId": "820c213f-5d9e-4ec2-f7b7-60947177223d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross Validation Scores are [0.96666667 1.         0.93333333 0.96666667 1.        ]\n",
            "Average Cross Validation score: 0.9733333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When comparing different cross-validation techniques on the Iris dataset, each method offers unique advantages and potential insights into model performance. Here's an inference based on using these four methods:\n",
        "\n",
        "1. **Hold Out Cross-Validation**:\n",
        "    - **Method**: The dataset is split into two parts: training and testing. Typically, a common split is 80/20 or 70/30.\n",
        "    - **Inference**: This method is simple and quick but can be subject to variability depending on the split. If the training and testing sets are not representative, the model performance might be misleading. It provides a snapshot of model performance but doesn't utilize the entire dataset for training.\n",
        "\n",
        "2. **K-Fold Cross-Validation**:\n",
        "    - **Method**: The dataset is divided into `k` equal parts. The model is trained on `k-1` parts and tested on the remaining part. This process is repeated `k` times, with each part used exactly once as the testing set.\n",
        "    - **Inference**: K-Fold cross-validation provides a more reliable estimate of model performance compared to hold-out validation. By training and testing on different subsets of the data, it reduces the variance in performance estimation. It ensures that every data point is used for both training and testing, providing a more comprehensive assessment.\n",
        "\n",
        "3. **Stratified K-Fold Cross-Validation**:\n",
        "    - **Method**: Similar to K-Fold, but the data is split in such a way that each fold has approximately the same proportion of classes as the entire dataset.\n",
        "    - **Inference**: Stratified K-Fold is especially useful for imbalanced datasets. For the Iris dataset, which has balanced classes, it ensures that each fold is representative of the overall class distribution. This typically leads to more stable and reliable performance metrics compared to regular K-Fold, especially if there are any minor imbalances.\n",
        "\n",
        "4. **Leave One Out Cross-Validation (LOOCV)**:\n",
        "    - **Method**: Each data point is used once as a test set while the remaining data points are used as the training set. This process is repeated for every data point in the dataset.\n",
        "    - **Inference**: LOOCV uses the maximum amount of data for training in each iteration, providing a very thorough assessment. However, it is computationally expensive and can be impractical for large datasets. For the Iris dataset, LOOCV would be feasible and could provide very detailed insights into model performance but might overestimate variance due to the high number of splits.\n",
        "\n",
        "**Overall Comparison**:\n",
        "- **Hold Out**: Quick and simple but less reliable due to potential data split variability.\n",
        "- **K-Fold**: Balances between computational efficiency and reliable performance estimation.\n",
        "- **Stratified K-Fold**: Enhances K-Fold by ensuring class distribution consistency across folds, providing more stable results.\n",
        "- **LOOCV**: Provides the most detailed and least biased performance estimate but is computationally intensive.\n",
        "\n",
        "For the Iris dataset, which is relatively small and balanced, **Stratified K-Fold** cross-validation often strikes the best balance between reliability and computational efficiency, ensuring that each fold is representative of the overall class distribution."
      ],
      "metadata": {
        "id": "Mk4NOGYgspwS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPERIMENT 4"
      ],
      "metadata": {
        "id": "srZCd1Vx46sp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import necessary libraries"
      ],
      "metadata": {
        "id": "jHohcn6_-37J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ],
      "metadata": {
        "id": "3msbjuJL497s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and preprocess the MNIST dataset"
      ],
      "metadata": {
        "id": "pdo2T5aP-920"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MNIST dataset from sklearn\n",
        "mnist = fetch_openml('mnist_784')\n",
        "\n",
        "# Extract features and labels\n",
        "X = mnist.data\n",
        "y = mnist.target.astype(int)  # Ensure labels are integers\n",
        "\n",
        "# Reshape the data for the CNN model\n",
        "X = X.values.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train_encoded = to_categorical(y_train, num_classes=10)\n",
        "y_test_encoded = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# Preprocess the data by scaling the features for NN model\n",
        "scaler = StandardScaler()\n",
        "X_train_flat = X_train.reshape(-1, 784)\n",
        "X_test_flat = X_test.reshape(-1, 784)\n",
        "X_train_scaled = scaler.fit_transform(X_train_flat)\n",
        "X_test_scaled = scaler.transform(X_test_flat)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEzFbBHT5p0g",
        "outputId": "6ea4473c-5c07-4b2d-d477-10ee49227158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the dense neural network model"
      ],
      "metadata": {
        "id": "NijyVFhU_N8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nn_model = Sequential()\n",
        "nn_model.add(Dense(45, input_dim=784, activation='relu'))\n",
        "nn_model.add(Dropout(0.3))\n",
        "nn_model.add(Dense(35, activation='relu'))\n",
        "nn_model.add(Dense(23, activation='relu'))\n",
        "nn_model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the dense model with Adam optimizer\n",
        "nn_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the dense model\n",
        "nn_model.fit(X_train_scaled, y_train_encoded, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the dense model\n",
        "loss, accuracy = nn_model.evaluate(X_test_scaled, y_test_encoded)\n",
        "print(\"Dense Model Accuracy:\", accuracy)\n",
        "\n",
        "# Make predictions with the dense model\n",
        "y_pred_encoded = nn_model.predict(X_test_scaled)\n",
        "y_pred = np.argmax(y_pred_encoded, axis=1)\n",
        "\n",
        "# Print classification report and confusion matrix for the dense model\n",
        "print(\"Dense Model Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Dense Model Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1mXIiWN_BCc",
        "outputId": "29d12daf-b6a5-40a0-f1db-b469dfacebca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.7388 - loss: 0.8322 - val_accuracy: 0.9324 - val_loss: 0.2430\n",
            "Epoch 2/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9061 - loss: 0.3142 - val_accuracy: 0.9400 - val_loss: 0.2648\n",
            "Epoch 3/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9218 - loss: 0.2687 - val_accuracy: 0.9464 - val_loss: 0.2273\n",
            "Epoch 4/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9287 - loss: 0.2383 - val_accuracy: 0.9503 - val_loss: 0.2162\n",
            "Epoch 5/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9329 - loss: 0.2243 - val_accuracy: 0.9513 - val_loss: 0.2476\n",
            "Epoch 6/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9402 - loss: 0.2018 - val_accuracy: 0.9531 - val_loss: 0.2452\n",
            "Epoch 7/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9366 - loss: 0.2011 - val_accuracy: 0.9552 - val_loss: 0.1957\n",
            "Epoch 8/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9405 - loss: 0.1951 - val_accuracy: 0.9551 - val_loss: 0.2224\n",
            "Epoch 9/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9470 - loss: 0.1727 - val_accuracy: 0.9540 - val_loss: 0.1932\n",
            "Epoch 10/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9476 - loss: 0.1741 - val_accuracy: 0.9546 - val_loss: 0.2163\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9586 - loss: 0.2013\n",
            "Dense Model Accuracy: 0.9580000042915344\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Dense Model Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.98      1343\n",
            "           1       0.99      0.97      0.98      1600\n",
            "           2       0.96      0.95      0.95      1380\n",
            "           3       0.96      0.94      0.95      1433\n",
            "           4       0.94      0.96      0.95      1295\n",
            "           5       0.96      0.95      0.96      1273\n",
            "           6       0.96      0.98      0.97      1396\n",
            "           7       0.93      0.98      0.95      1503\n",
            "           8       0.96      0.94      0.95      1357\n",
            "           9       0.95      0.94      0.95      1420\n",
            "\n",
            "    accuracy                           0.96     14000\n",
            "   macro avg       0.96      0.96      0.96     14000\n",
            "weighted avg       0.96      0.96      0.96     14000\n",
            "\n",
            "Dense Model Confusion Matrix:\n",
            "[[1309    0    4    0    1    4   13    4    8    0]\n",
            " [   0 1556    8    7    2    1    0    9   15    2]\n",
            " [   4    5 1309    7   11    5   13   17    7    2]\n",
            " [   0    0   13 1350    2   20    2   36    4    6]\n",
            " [   2    1    5    0 1239    1    7    5    4   31]\n",
            " [   0    0    2   24    6 1215   13    2    6    5]\n",
            " [   4    0    3    0   11    8 1364    1    5    0]\n",
            " [   3    2    9    1    7    2    0 1467    2   10]\n",
            " [   6    9   15   13    6   12    7   12 1270    7]\n",
            " [   7    5    1    8   28    3    1   29    5 1333]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the convolutional neural network model"
      ],
      "metadata": {
        "id": "Lxju-XfTASJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = Sequential()\n",
        "cnn_model.add(Conv2D(28, (5, 5), padding='same', input_shape=X_train.shape[1:]))\n",
        "cnn_model.add(Activation('relu'))\n",
        "cnn_model.add(BatchNormalization())\n",
        "cnn_model.add(Conv2D(28, (5, 5)))\n",
        "cnn_model.add(Activation('relu'))\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn_model.add(Dropout(0.25))\n",
        "cnn_model.add(Conv2D(32, (5, 5), padding='same'))\n",
        "cnn_model.add(Activation('relu'))\n",
        "cnn_model.add(BatchNormalization())\n",
        "cnn_model.add(Conv2D(32, (5, 5)))\n",
        "cnn_model.add(Activation('relu'))\n",
        "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn_model.add(Dropout(0.25))\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(512))\n",
        "cnn_model.add(Activation('relu'))\n",
        "cnn_model.add(Dropout(0.25))\n",
        "cnn_model.add(Dense(10))\n",
        "cnn_model.add(Activation('softmax'))\n",
        "\n",
        "# Compile the CNN model with Adam optimizer\n",
        "cnn_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the CNN model\n",
        "cnn_model.fit(X_train, y_train_encoded, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the CNN model\n",
        "loss, accuracy = cnn_model.evaluate(X_test, y_test_encoded)\n",
        "print(\"CNN Model Accuracy:\", accuracy)\n",
        "\n",
        "# Make predictions with the CNN model\n",
        "y_pred_encoded = cnn_model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_encoded, axis=1)\n",
        "\n",
        "# Print classification report and confusion matrix for the CNN model\n",
        "print(\"CNN Model Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"CNN Model Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYwa8Lf9ALXh",
        "outputId": "839cc74e-5343-404f-a871-76dedd394cba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.8932 - loss: 0.3533 - val_accuracy: 0.9744 - val_loss: 0.0845\n",
            "Epoch 2/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9797 - loss: 0.0691 - val_accuracy: 0.9860 - val_loss: 0.0448\n",
            "Epoch 3/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9839 - loss: 0.0539 - val_accuracy: 0.9913 - val_loss: 0.0304\n",
            "Epoch 4/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9855 - loss: 0.0491 - val_accuracy: 0.9872 - val_loss: 0.0412\n",
            "Epoch 5/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9872 - loss: 0.0435 - val_accuracy: 0.9885 - val_loss: 0.0431\n",
            "Epoch 6/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9875 - loss: 0.0428 - val_accuracy: 0.9915 - val_loss: 0.0333\n",
            "Epoch 7/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9904 - loss: 0.0338 - val_accuracy: 0.9891 - val_loss: 0.0363\n",
            "Epoch 8/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9906 - loss: 0.0342 - val_accuracy: 0.9910 - val_loss: 0.0328\n",
            "Epoch 9/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9925 - loss: 0.0268 - val_accuracy: 0.9917 - val_loss: 0.0331\n",
            "Epoch 10/10\n",
            "\u001b[1m1400/1400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9912 - loss: 0.0304 - val_accuracy: 0.9903 - val_loss: 0.0336\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9909 - loss: 0.0329\n",
            "CNN Model Accuracy: 0.9912857413291931\n",
            "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "CNN Model Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1343\n",
            "           1       0.99      1.00      0.99      1600\n",
            "           2       1.00      0.98      0.99      1380\n",
            "           3       0.99      1.00      0.99      1433\n",
            "           4       0.98      0.99      0.99      1295\n",
            "           5       1.00      0.99      0.99      1273\n",
            "           6       1.00      0.99      0.99      1396\n",
            "           7       0.98      1.00      0.99      1503\n",
            "           8       0.99      0.99      0.99      1357\n",
            "           9       0.99      0.98      0.99      1420\n",
            "\n",
            "    accuracy                           0.99     14000\n",
            "   macro avg       0.99      0.99      0.99     14000\n",
            "weighted avg       0.99      0.99      0.99     14000\n",
            "\n",
            "CNN Model Confusion Matrix:\n",
            "[[1339    0    1    0    0    0    1    1    1    0]\n",
            " [   0 1595    0    0    0    0    0    4    1    0]\n",
            " [   0    4 1357    4    0    0    0   13    2    0]\n",
            " [   0    1    0 1426    0    2    0    3    0    1]\n",
            " [   0    0    1    0 1286    0    0    4    0    4]\n",
            " [   0    2    1    5    0 1260    2    0    3    0]\n",
            " [   1    3    0    0    2    3 1383    0    4    0]\n",
            " [   0    2    1    0    3    0    0 1496    0    1]\n",
            " [   1    1    2    3    1    1    0    3 1340    5]\n",
            " [   0    0    0    1   14    0    0    5    4 1396]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPERIMENT 5 PRIMA DIABETES"
      ],
      "metadata": {
        "id": "yTT8WrADrUVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# load the dataset\n",
        "dataset = pd.read_csv('/content/drive/My Drive/Colab Notebooks/deep learning/primadiabetes.csv', delimiter=',')\n",
        "\n",
        "# split into input (X) and output (y) variables\n",
        "X = dataset.iloc[:, 0:8].values  # Use .iloc to access by index\n",
        "y = dataset.iloc[:, 8].values\n",
        "\n",
        "# print the split data\n",
        "print(X)\n",
        "print(y)\n",
        "\n",
        "# define the keras model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# compile the keras model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# fit the keras model on the dataset\n",
        "model.fit(X, y, epochs=150, batch_size=10)\n",
        "\n",
        "# evaluate the keras model\n",
        "_, accuracy = model.evaluate(X, y)\n",
        "print('Accuracy: %.2f' % (accuracy * 100))\n",
        "\n",
        "# make probability predictions with the model\n",
        "Xp = np.array([[6.0, 158.0, 72.0, 35.0, 0.0, 55.5, 0.627, 50.0]])\n",
        "Yp = model.predict(Xp)\n",
        "print(Xp[0], Yp[0])\n",
        "\n",
        "# save the model\n",
        "model.save(\"First_ANN\")\n"
      ],
      "metadata": {
        "id": "DGQzIN25ARUo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b90985e3-9137-413b-bfd2-7f7cb48f57af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  6.    148.     72.    ...  33.6     0.627  50.   ]\n",
            " [  1.     85.     66.    ...  26.6     0.351  31.   ]\n",
            " [  8.    183.     64.    ...  23.3     0.672  32.   ]\n",
            " ...\n",
            " [  5.    121.     72.    ...  26.2     0.245  30.   ]\n",
            " [  1.    126.     60.    ...  30.1     0.349  47.   ]\n",
            " [  1.     93.     70.    ...  30.4     0.315  23.   ]]\n",
            "[1 0 1 0 1 0 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0\n",
            " 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 1 0\n",
            " 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1\n",
            " 1 0 0 1 1 1 0 0 0 1 0 0 0 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
            " 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 0\n",
            " 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 0 1 1 1 1\n",
            " 0 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
            " 1 0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 1 1 0 0\n",
            " 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 0 1 0 1 1 1 0 0 1 0 1 0 0 0 1\n",
            " 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1 1 0 0 1 0 0 1 0 0 1\n",
            " 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 1 0 1 0 1 0 1\n",
            " 0 1 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1\n",
            " 1 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1\n",
            " 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0\n",
            " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 1 0 1 0 1 0\n",
            " 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1 1 1 0\n",
            " 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 1 1\n",
            " 0 0 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1\n",
            " 1 0 0 1 0 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 1 0 0 0 0 1 0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.6231 - loss: 9.3262\n",
            "Epoch 2/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5867 - loss: 2.6929\n",
            "Epoch 3/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5783 - loss: 1.0222\n",
            "Epoch 4/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6369 - loss: 0.7087\n",
            "Epoch 5/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6677 - loss: 0.6495\n",
            "Epoch 6/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6972 - loss: 0.6058\n",
            "Epoch 7/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6641 - loss: 0.7199\n",
            "Epoch 8/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6438 - loss: 0.6641\n",
            "Epoch 9/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6577 - loss: 0.6720\n",
            "Epoch 10/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6765 - loss: 0.6644\n",
            "Epoch 11/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6838 - loss: 0.6086\n",
            "Epoch 12/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6388 - loss: 0.6887\n",
            "Epoch 13/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6145 - loss: 0.7890\n",
            "Epoch 14/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6776 - loss: 0.6428\n",
            "Epoch 15/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6834 - loss: 0.5885\n",
            "Epoch 16/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7101 - loss: 0.6002\n",
            "Epoch 17/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7205 - loss: 0.5702\n",
            "Epoch 18/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7317 - loss: 0.5623\n",
            "Epoch 19/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6608 - loss: 0.6068\n",
            "Epoch 20/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7315 - loss: 0.5993\n",
            "Epoch 21/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7129 - loss: 0.5793\n",
            "Epoch 22/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6898 - loss: 0.5935\n",
            "Epoch 23/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6524 - loss: 0.7066\n",
            "Epoch 24/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7191 - loss: 0.6153\n",
            "Epoch 25/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7206 - loss: 0.5915\n",
            "Epoch 26/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6875 - loss: 0.6117\n",
            "Epoch 27/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6965 - loss: 0.5762\n",
            "Epoch 28/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7095 - loss: 0.5902\n",
            "Epoch 29/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7208 - loss: 0.5651\n",
            "Epoch 30/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6874 - loss: 0.5705\n",
            "Epoch 31/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7284 - loss: 0.5435\n",
            "Epoch 32/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7353 - loss: 0.5671\n",
            "Epoch 33/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7019 - loss: 0.5864\n",
            "Epoch 34/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7143 - loss: 0.6023\n",
            "Epoch 35/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7349 - loss: 0.5710\n",
            "Epoch 36/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7399 - loss: 0.5296\n",
            "Epoch 37/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7411 - loss: 0.5504\n",
            "Epoch 38/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7241 - loss: 0.5584\n",
            "Epoch 39/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7094 - loss: 0.5833\n",
            "Epoch 40/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7434 - loss: 0.5703\n",
            "Epoch 41/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6762 - loss: 0.6215\n",
            "Epoch 42/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7228 - loss: 0.5593\n",
            "Epoch 43/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6912 - loss: 0.5788\n",
            "Epoch 44/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7287 - loss: 0.5644\n",
            "Epoch 45/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7262 - loss: 0.5634\n",
            "Epoch 46/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7653 - loss: 0.4821\n",
            "Epoch 47/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7185 - loss: 0.5616\n",
            "Epoch 48/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7171 - loss: 0.5781\n",
            "Epoch 49/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7202 - loss: 0.5410\n",
            "Epoch 50/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7264 - loss: 0.5466\n",
            "Epoch 51/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7559 - loss: 0.5400\n",
            "Epoch 52/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7633 - loss: 0.5194\n",
            "Epoch 53/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7344 - loss: 0.5383\n",
            "Epoch 54/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7466 - loss: 0.5612\n",
            "Epoch 55/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7319 - loss: 0.5269\n",
            "Epoch 56/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7276 - loss: 0.5598\n",
            "Epoch 57/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7254 - loss: 0.5564\n",
            "Epoch 58/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7319 - loss: 0.5658\n",
            "Epoch 59/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6941 - loss: 0.5864\n",
            "Epoch 60/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7554 - loss: 0.5177\n",
            "Epoch 61/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7188 - loss: 0.5485\n",
            "Epoch 62/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7498 - loss: 0.5141\n",
            "Epoch 63/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7621 - loss: 0.5048\n",
            "Epoch 64/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7075 - loss: 0.6154\n",
            "Epoch 65/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7238 - loss: 0.5424\n",
            "Epoch 66/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6963 - loss: 0.5700\n",
            "Epoch 67/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7506 - loss: 0.5136\n",
            "Epoch 68/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7773 - loss: 0.4908\n",
            "Epoch 69/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7800 - loss: 0.4767\n",
            "Epoch 70/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7379 - loss: 0.5492\n",
            "Epoch 71/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7680 - loss: 0.5077\n",
            "Epoch 72/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7107 - loss: 0.6322\n",
            "Epoch 73/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7571 - loss: 0.5093\n",
            "Epoch 74/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7605 - loss: 0.5208\n",
            "Epoch 75/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7326 - loss: 0.5192\n",
            "Epoch 76/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7559 - loss: 0.5233\n",
            "Epoch 77/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7944 - loss: 0.4873\n",
            "Epoch 78/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7720 - loss: 0.5181\n",
            "Epoch 79/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7540 - loss: 0.5087\n",
            "Epoch 80/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7524 - loss: 0.5084\n",
            "Epoch 81/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7351 - loss: 0.5143\n",
            "Epoch 82/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7779 - loss: 0.5115\n",
            "Epoch 83/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7503 - loss: 0.5266\n",
            "Epoch 84/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7481 - loss: 0.5243\n",
            "Epoch 85/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7705 - loss: 0.4904\n",
            "Epoch 86/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7438 - loss: 0.5144\n",
            "Epoch 87/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7536 - loss: 0.4903\n",
            "Epoch 88/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7447 - loss: 0.5090\n",
            "Epoch 89/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7523 - loss: 0.4920\n",
            "Epoch 90/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7562 - loss: 0.4882\n",
            "Epoch 91/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7594 - loss: 0.4942\n",
            "Epoch 92/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7687 - loss: 0.4931\n",
            "Epoch 93/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7457 - loss: 0.4970\n",
            "Epoch 94/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7384 - loss: 0.5601\n",
            "Epoch 95/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7915 - loss: 0.4623\n",
            "Epoch 96/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7623 - loss: 0.4942\n",
            "Epoch 97/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7447 - loss: 0.5108\n",
            "Epoch 98/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7744 - loss: 0.4698\n",
            "Epoch 99/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7550 - loss: 0.5747\n",
            "Epoch 100/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7793 - loss: 0.4877\n",
            "Epoch 101/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7562 - loss: 0.4812\n",
            "Epoch 102/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7283 - loss: 0.5430\n",
            "Epoch 103/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7691 - loss: 0.4877\n",
            "Epoch 104/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7698 - loss: 0.4656\n",
            "Epoch 105/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7532 - loss: 0.5027\n",
            "Epoch 106/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7514 - loss: 0.5148\n",
            "Epoch 107/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7502 - loss: 0.5228\n",
            "Epoch 108/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7626 - loss: 0.5029\n",
            "Epoch 109/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7873 - loss: 0.5029\n",
            "Epoch 110/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7730 - loss: 0.4547\n",
            "Epoch 111/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7336 - loss: 0.5089\n",
            "Epoch 112/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7622 - loss: 0.5109\n",
            "Epoch 113/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7636 - loss: 0.4881\n",
            "Epoch 114/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7762 - loss: 0.4804\n",
            "Epoch 115/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7733 - loss: 0.4683\n",
            "Epoch 116/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7622 - loss: 0.4985\n",
            "Epoch 117/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7754 - loss: 0.5105\n",
            "Epoch 118/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7775 - loss: 0.4695\n",
            "Epoch 119/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7405 - loss: 0.5005\n",
            "Epoch 120/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7862 - loss: 0.4591\n",
            "Epoch 121/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7721 - loss: 0.4888\n",
            "Epoch 122/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7813 - loss: 0.4865\n",
            "Epoch 123/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7559 - loss: 0.4793\n",
            "Epoch 124/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7343 - loss: 0.5079\n",
            "Epoch 125/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7437 - loss: 0.5055\n",
            "Epoch 126/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7458 - loss: 0.5427\n",
            "Epoch 127/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7828 - loss: 0.4661\n",
            "Epoch 128/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7599 - loss: 0.5007\n",
            "Epoch 129/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7797 - loss: 0.4745\n",
            "Epoch 130/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7549 - loss: 0.4866\n",
            "Epoch 131/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7390 - loss: 0.5272\n",
            "Epoch 132/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7375 - loss: 0.5069\n",
            "Epoch 133/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7860 - loss: 0.4470\n",
            "Epoch 134/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7735 - loss: 0.4643\n",
            "Epoch 135/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7568 - loss: 0.5067\n",
            "Epoch 136/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7729 - loss: 0.4845\n",
            "Epoch 137/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7663 - loss: 0.4810\n",
            "Epoch 138/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7492 - loss: 0.5184\n",
            "Epoch 139/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7612 - loss: 0.4696\n",
            "Epoch 140/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7869 - loss: 0.4751\n",
            "Epoch 141/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7712 - loss: 0.4701\n",
            "Epoch 142/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7739 - loss: 0.4582\n",
            "Epoch 143/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7828 - loss: 0.4784\n",
            "Epoch 144/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8157 - loss: 0.4362\n",
            "Epoch 145/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7771 - loss: 0.4688\n",
            "Epoch 146/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7896 - loss: 0.4656\n",
            "Epoch 147/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7678 - loss: 0.4918\n",
            "Epoch 148/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7702 - loss: 0.4905\n",
            "Epoch 149/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7827 - loss: 0.4878\n",
            "Epoch 150/150\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8088 - loss: 0.4603\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7717 - loss: 0.4807   \n",
            "Accuracy: 78.65\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
            "[  6.    158.     72.     35.      0.     55.5     0.627  50.   ] [0.9137718]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=First_ANN.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-60edef144eb9>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# save the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"First_ANN\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, zipped, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         )\n\u001b[0;32m--> 109\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"Invalid filepath extension for saving. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;34m\"Please add either a `.keras` extension for the native Keras \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=First_ANN."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPERIMENT 6 - ACTIVATION FUNCTION"
      ],
      "metadata": {
        "id": "xGRnQvavrZxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid_function(x):\n",
        "    z = 1 / (1 + np.exp(-x))\n",
        "    return z\n",
        "\n",
        "print(sigmoid_function(7))\n",
        "print(sigmoid_function(-22))\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def tanh_function(x):\n",
        "    z = (2 / (1 + np.exp(-2 * x))) - 1\n",
        "    return z\n",
        "\n",
        "print(tanh_function(0.5))\n",
        "print(tanh_function(-1))\n",
        "\n",
        "def relu_function(x):\n",
        "    if x < 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "print(relu_function(7))\n",
        "print(relu_function(-7))\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def softmax_function(x):\n",
        "    z = np.exp(x)\n",
        "    z = z / z.sum()\n",
        "    return z\n",
        "\n",
        "print(softmax_function([0.8, 1.2, 3.1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4S-b5oU60ecN",
        "outputId": "0c5d5f55-be7e-4789-a1cd-aa63c35dfe3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9990889488055994\n",
            "2.7894680920908113e-10\n",
            "0.4621171572600098\n",
            "-0.7615941559557649\n",
            "7\n",
            "0\n",
            "[0.08021815 0.11967141 0.80011044]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Loading the dataset\n",
        "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/deep learning/housepricedata.csv')\n",
        "\n",
        "# Converting categorical columns to numeric using LabelEncoder (if necessary)\n",
        "# Assuming 'yes' is part of a categorical column, replace 'your_categorical_column' with actual column names\n",
        "for column in df.columns:\n",
        "    if df[column].dtype == 'object':  # Check if the column is categorical\n",
        "        labelencoder = LabelEncoder()\n",
        "        df[column] = labelencoder.fit_transform(df[column])\n",
        "\n",
        "# Preparing the dataset\n",
        "dataset = df.values\n",
        "\n",
        "# Splitting the dataset into X (features) and Y (target)\n",
        "X = dataset[:, 0:10]\n",
        "Y = dataset[:, 10]\n",
        "\n",
        "# Scaling the features using MinMaxScaler\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X)\n",
        "\n",
        "# Splitting the data into training, validation, and test sets\n",
        "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, Y, test_size=0.3)\n",
        "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)\n",
        "\n",
        "# Printing the shapes of the resulting datasets\n",
        "print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)\n",
        "# Output should be: (1022, 10) (219, 10) (219, 10) (1022,) (219,) (219,)\n",
        "\n",
        "# Initializing the Neural Network\n",
        "model = Sequential([\n",
        "    Dense(32, activation='relu', input_shape=(10,)),  # First hidden layer with 32 neurons\n",
        "    Dense(32, activation='relu'),  # Second hidden layer with 32 neurons\n",
        "    Dense(1, activation='sigmoid'),  # Output layer with 1 neuron\n",
        "])\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=32, epochs=100,\n",
        "          validation_data=(X_val, Y_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUDClT9IreHg",
        "outputId": "5e5364bf-a710-4797-8639-135498906bd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(381, 10) (82, 10) (82, 10) (381,) (82,) (82,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 100ms/step - accuracy: 0.2513 - loss: 0.6144 - val_accuracy: 0.2439 - val_loss: 0.6519\n",
            "Epoch 2/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2629 - loss: 0.6268 - val_accuracy: 0.2439 - val_loss: 0.6475\n",
            "Epoch 3/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2478 - loss: 0.5658 - val_accuracy: 0.2439 - val_loss: 0.6442\n",
            "Epoch 4/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2512 - loss: 0.5613 - val_accuracy: 0.2439 - val_loss: 0.6418\n",
            "Epoch 5/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2333 - loss: 0.5690 - val_accuracy: 0.2439 - val_loss: 0.6409\n",
            "Epoch 6/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1977 - loss: 0.5266 - val_accuracy: 0.2439 - val_loss: 0.6409\n",
            "Epoch 7/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2148 - loss: 0.5506 - val_accuracy: 0.2439 - val_loss: 0.6416\n",
            "Epoch 8/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2466 - loss: 0.5447 - val_accuracy: 0.2439 - val_loss: 0.6428\n",
            "Epoch 9/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2722 - loss: 0.5118 - val_accuracy: 0.2439 - val_loss: 0.6441\n",
            "Epoch 10/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2479 - loss: 0.5021 - val_accuracy: 0.2439 - val_loss: 0.6457\n",
            "Epoch 11/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2161 - loss: 0.5515 - val_accuracy: 0.2439 - val_loss: 0.6472\n",
            "Epoch 12/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2623 - loss: 0.4846 - val_accuracy: 0.2439 - val_loss: 0.6484\n",
            "Epoch 13/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2598 - loss: 0.5610 - val_accuracy: 0.2439 - val_loss: 0.6497\n",
            "Epoch 14/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2368 - loss: 0.4918 - val_accuracy: 0.2439 - val_loss: 0.6506\n",
            "Epoch 15/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2170 - loss: 0.4527 - val_accuracy: 0.2439 - val_loss: 0.6513\n",
            "Epoch 16/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2477 - loss: 0.4552 - val_accuracy: 0.2439 - val_loss: 0.6520\n",
            "Epoch 17/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2163 - loss: 0.4879 - val_accuracy: 0.2439 - val_loss: 0.6528\n",
            "Epoch 18/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2205 - loss: 0.5035 - val_accuracy: 0.2439 - val_loss: 0.6535\n",
            "Epoch 19/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2254 - loss: 0.5236 - val_accuracy: 0.2439 - val_loss: 0.6543\n",
            "Epoch 20/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2063 - loss: 0.5348 - val_accuracy: 0.2439 - val_loss: 0.6552\n",
            "Epoch 21/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2123 - loss: 0.4928 - val_accuracy: 0.2439 - val_loss: 0.6556\n",
            "Epoch 22/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2301 - loss: 0.5492 - val_accuracy: 0.2439 - val_loss: 0.6560\n",
            "Epoch 23/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2242 - loss: 0.5460 - val_accuracy: 0.2439 - val_loss: 0.6565\n",
            "Epoch 24/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2582 - loss: 0.3905 - val_accuracy: 0.2439 - val_loss: 0.6560\n",
            "Epoch 25/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2371 - loss: 0.5117 - val_accuracy: 0.2439 - val_loss: 0.6562\n",
            "Epoch 26/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2320 - loss: 0.4596 - val_accuracy: 0.2439 - val_loss: 0.6556\n",
            "Epoch 27/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2426 - loss: 0.5089 - val_accuracy: 0.2439 - val_loss: 0.6558\n",
            "Epoch 28/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2270 - loss: 0.4644 - val_accuracy: 0.2439 - val_loss: 0.6556\n",
            "Epoch 29/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2142 - loss: 0.4566 - val_accuracy: 0.2439 - val_loss: 0.6554\n",
            "Epoch 30/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2328 - loss: 0.5448 - val_accuracy: 0.2439 - val_loss: 0.6559\n",
            "Epoch 31/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2160 - loss: 0.4806 - val_accuracy: 0.2439 - val_loss: 0.6562\n",
            "Epoch 32/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2341 - loss: 0.5247 - val_accuracy: 0.2439 - val_loss: 0.6563\n",
            "Epoch 33/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2407 - loss: 0.4914 - val_accuracy: 0.2439 - val_loss: 0.6565\n",
            "Epoch 34/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2627 - loss: 0.4716 - val_accuracy: 0.2439 - val_loss: 0.6566\n",
            "Epoch 35/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2544 - loss: 0.5049 - val_accuracy: 0.2439 - val_loss: 0.6568\n",
            "Epoch 36/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2549 - loss: 0.4654 - val_accuracy: 0.2439 - val_loss: 0.6572\n",
            "Epoch 37/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2205 - loss: 0.3852 - val_accuracy: 0.2439 - val_loss: 0.6567\n",
            "Epoch 38/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2410 - loss: 0.4809 - val_accuracy: 0.2439 - val_loss: 0.6570\n",
            "Epoch 39/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2665 - loss: 0.4348 - val_accuracy: 0.2561 - val_loss: 0.6565\n",
            "Epoch 40/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2611 - loss: 0.4518 - val_accuracy: 0.2561 - val_loss: 0.6574\n",
            "Epoch 41/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2395 - loss: 0.3848 - val_accuracy: 0.2561 - val_loss: 0.6570\n",
            "Epoch 42/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2453 - loss: 0.4120 - val_accuracy: 0.2683 - val_loss: 0.6570\n",
            "Epoch 43/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2154 - loss: 0.4752 - val_accuracy: 0.2683 - val_loss: 0.6584\n",
            "Epoch 44/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2395 - loss: 0.3420 - val_accuracy: 0.2683 - val_loss: 0.6578\n",
            "Epoch 45/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2394 - loss: 0.3756 - val_accuracy: 0.2683 - val_loss: 0.6579\n",
            "Epoch 46/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2356 - loss: 0.3129 - val_accuracy: 0.2683 - val_loss: 0.6580\n",
            "Epoch 47/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2500 - loss: 0.3366 - val_accuracy: 0.2683 - val_loss: 0.6577\n",
            "Epoch 48/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2639 - loss: 0.4091 - val_accuracy: 0.2683 - val_loss: 0.6587\n",
            "Epoch 49/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2529 - loss: 0.4568 - val_accuracy: 0.2683 - val_loss: 0.6599\n",
            "Epoch 50/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2450 - loss: 0.2356 - val_accuracy: 0.2683 - val_loss: 0.6601\n",
            "Epoch 51/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2710 - loss: 0.4353 - val_accuracy: 0.2683 - val_loss: 0.6622\n",
            "Epoch 52/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2594 - loss: 0.3550 - val_accuracy: 0.2683 - val_loss: 0.6626\n",
            "Epoch 53/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2321 - loss: 0.4318 - val_accuracy: 0.2683 - val_loss: 0.6641\n",
            "Epoch 54/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2653 - loss: 0.2886 - val_accuracy: 0.2561 - val_loss: 0.6652\n",
            "Epoch 55/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2565 - loss: 0.3221 - val_accuracy: 0.2561 - val_loss: 0.6648\n",
            "Epoch 56/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2967 - loss: 0.2998 - val_accuracy: 0.2561 - val_loss: 0.6659\n",
            "Epoch 57/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2646 - loss: 0.4254 - val_accuracy: 0.2561 - val_loss: 0.6683\n",
            "Epoch 58/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2821 - loss: 0.3172 - val_accuracy: 0.2683 - val_loss: 0.6692\n",
            "Epoch 59/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2710 - loss: 0.2097 - val_accuracy: 0.2683 - val_loss: 0.6688\n",
            "Epoch 60/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2563 - loss: 0.2377 - val_accuracy: 0.2805 - val_loss: 0.6683\n",
            "Epoch 61/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2382 - loss: 0.2258 - val_accuracy: 0.2805 - val_loss: 0.6691\n",
            "Epoch 62/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2704 - loss: 0.3660 - val_accuracy: 0.2805 - val_loss: 0.6719\n",
            "Epoch 63/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2708 - loss: 0.3473 - val_accuracy: 0.2805 - val_loss: 0.6739\n",
            "Epoch 64/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2562 - loss: 0.3273 - val_accuracy: 0.2805 - val_loss: 0.6743\n",
            "Epoch 65/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2721 - loss: 0.3135 - val_accuracy: 0.2805 - val_loss: 0.6779\n",
            "Epoch 66/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2636 - loss: 0.2654 - val_accuracy: 0.2805 - val_loss: 0.6788\n",
            "Epoch 67/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2368 - loss: 0.2824 - val_accuracy: 0.2805 - val_loss: 0.6811\n",
            "Epoch 68/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2320 - loss: 0.3643 - val_accuracy: 0.2805 - val_loss: 0.6834\n",
            "Epoch 69/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2772 - loss: 0.3489 - val_accuracy: 0.2805 - val_loss: 0.6852\n",
            "Epoch 70/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2799 - loss: 0.4258 - val_accuracy: 0.2805 - val_loss: 0.6886\n",
            "Epoch 71/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2739 - loss: 0.2586 - val_accuracy: 0.2805 - val_loss: 0.6874\n",
            "Epoch 72/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2780 - loss: 0.3352 - val_accuracy: 0.2805 - val_loss: 0.6897\n",
            "Epoch 73/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2705 - loss: 0.3561 - val_accuracy: 0.2805 - val_loss: 0.6921\n",
            "Epoch 74/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2710 - loss: 0.3149 - val_accuracy: 0.2805 - val_loss: 0.6956\n",
            "Epoch 75/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2611 - loss: 0.2743 - val_accuracy: 0.2805 - val_loss: 0.6946\n",
            "Epoch 76/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2911 - loss: 0.2570 - val_accuracy: 0.2805 - val_loss: 0.6973\n",
            "Epoch 77/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3124 - loss: 0.2233 - val_accuracy: 0.2927 - val_loss: 0.6984\n",
            "Epoch 78/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2729 - loss: 0.2696 - val_accuracy: 0.2927 - val_loss: 0.7009\n",
            "Epoch 79/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2958 - loss: 0.3071 - val_accuracy: 0.2927 - val_loss: 0.7037\n",
            "Epoch 80/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2558 - loss: 0.0049 - val_accuracy: 0.3049 - val_loss: 0.7012\n",
            "Epoch 81/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2920 - loss: 0.2490 - val_accuracy: 0.3049 - val_loss: 0.7072\n",
            "Epoch 82/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3294 - loss: 0.2701 - val_accuracy: 0.3049 - val_loss: 0.7097\n",
            "Epoch 83/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2771 - loss: 0.3308 - val_accuracy: 0.3171 - val_loss: 0.7105\n",
            "Epoch 84/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3008 - loss: 0.0039 - val_accuracy: 0.3171 - val_loss: 0.7100\n",
            "Epoch 85/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2929 - loss: 0.1585 - val_accuracy: 0.3171 - val_loss: 0.7151\n",
            "Epoch 86/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2945 - loss: 0.2139 - val_accuracy: 0.3171 - val_loss: 0.7173\n",
            "Epoch 87/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2882 - loss: 0.1966 - val_accuracy: 0.3171 - val_loss: 0.7201\n",
            "Epoch 88/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3315 - loss: 0.1354 - val_accuracy: 0.3415 - val_loss: 0.7224\n",
            "Epoch 89/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2745 - loss: 0.1842 - val_accuracy: 0.3415 - val_loss: 0.7244\n",
            "Epoch 90/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3014 - loss: -0.0266 - val_accuracy: 0.3415 - val_loss: 0.7249\n",
            "Epoch 91/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3083 - loss: 0.3187 - val_accuracy: 0.3537 - val_loss: 0.7297\n",
            "Epoch 92/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3102 - loss: -3.9812e-04 - val_accuracy: 0.3537 - val_loss: 0.7307\n",
            "Epoch 93/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3027 - loss: 0.0994 - val_accuracy: 0.3537 - val_loss: 0.7338\n",
            "Epoch 94/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3294 - loss: 0.3264 - val_accuracy: 0.3537 - val_loss: 0.7396\n",
            "Epoch 95/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3273 - loss: 0.1501 - val_accuracy: 0.3537 - val_loss: 0.7440\n",
            "Epoch 96/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3209 - loss: 0.0380 - val_accuracy: 0.3780 - val_loss: 0.7442\n",
            "Epoch 97/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3552 - loss: 0.2581 - val_accuracy: 0.3659 - val_loss: 0.7498\n",
            "Epoch 98/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3351 - loss: 0.1248 - val_accuracy: 0.3780 - val_loss: 0.7478\n",
            "Epoch 99/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3700 - loss: -0.1062 - val_accuracy: 0.4024 - val_loss: 0.7465\n",
            "Epoch 100/100\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3933 - loss: 0.0973 - val_accuracy: 0.4024 - val_loss: 0.7513\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x797ec9fd9060>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# Load the Fashion MNIST dataset\n",
        "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize the pixel values to a range between 0 and 1\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "# Flatten the images into 1D arrays\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "\n",
        "# Define the autoencoder architecture\n",
        "encoding_dim = 32 # Dimensionality of the encoded representations\n",
        "input_img = tf.keras.Input(shape=(784,))\n",
        "encoded = tf.keras.layers.Dense(encoding_dim, activation='relu')(input_img)\n",
        "decoded = tf.keras.layers.Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "# Create the autoencoder model\n",
        "autoencoder = tf.keras.Model(input_img, decoded)\n",
        "\n",
        "# Compile the model\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Train the autoencoder\n",
        "autoencoder.fit(x_train, x_train,\n",
        "epochs=50,\n",
        "batch_size=256,\n",
        "shuffle=True,\n",
        "validation_data=(x_test, x_test))\n",
        "\n",
        "# Predict reconstructed images\n",
        "decoded_imgs = autoencoder.predict(x_test)"
      ],
      "metadata": {
        "id": "sdNbPYa3tcs-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53fe9839-be04-4c77-970d-1bb216c5e53e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.4947 - val_loss: 0.3435\n",
            "Epoch 2/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3334 - val_loss: 0.3192\n",
            "Epoch 3/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3144 - val_loss: 0.3078\n",
            "Epoch 4/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3030 - val_loss: 0.3002\n",
            "Epoch 5/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2968 - val_loss: 0.2951\n",
            "Epoch 6/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2919 - val_loss: 0.2923\n",
            "Epoch 7/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2901 - val_loss: 0.2903\n",
            "Epoch 8/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2873 - val_loss: 0.2891\n",
            "Epoch 9/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2868 - val_loss: 0.2883\n",
            "Epoch 10/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2858 - val_loss: 0.2877\n",
            "Epoch 11/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2852 - val_loss: 0.2872\n",
            "Epoch 12/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2850 - val_loss: 0.2868\n",
            "Epoch 13/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2846 - val_loss: 0.2866\n",
            "Epoch 14/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2843 - val_loss: 0.2864\n",
            "Epoch 15/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2839 - val_loss: 0.2862\n",
            "Epoch 16/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2839 - val_loss: 0.2861\n",
            "Epoch 17/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2834 - val_loss: 0.2859\n",
            "Epoch 18/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2836 - val_loss: 0.2858\n",
            "Epoch 19/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2828 - val_loss: 0.2853\n",
            "Epoch 20/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2823 - val_loss: 0.2851\n",
            "Epoch 21/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2831 - val_loss: 0.2851\n",
            "Epoch 22/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2825 - val_loss: 0.2849\n",
            "Epoch 23/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2820 - val_loss: 0.2848\n",
            "Epoch 24/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2821 - val_loss: 0.2848\n",
            "Epoch 25/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2823 - val_loss: 0.2846\n",
            "Epoch 26/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2829 - val_loss: 0.2846\n",
            "Epoch 27/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2821 - val_loss: 0.2845\n",
            "Epoch 28/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2825 - val_loss: 0.2844\n",
            "Epoch 29/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2820 - val_loss: 0.2844\n",
            "Epoch 30/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2825 - val_loss: 0.2843\n",
            "Epoch 31/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2812 - val_loss: 0.2843\n",
            "Epoch 32/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2819 - val_loss: 0.2842\n",
            "Epoch 33/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2826 - val_loss: 0.2842\n",
            "Epoch 34/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2816 - val_loss: 0.2841\n",
            "Epoch 35/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2817 - val_loss: 0.2842\n",
            "Epoch 36/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2810 - val_loss: 0.2842\n",
            "Epoch 37/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2819 - val_loss: 0.2841\n",
            "Epoch 38/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2811 - val_loss: 0.2841\n",
            "Epoch 39/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2811 - val_loss: 0.2840\n",
            "Epoch 40/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2813 - val_loss: 0.2840\n",
            "Epoch 41/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2814 - val_loss: 0.2839\n",
            "Epoch 42/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2820 - val_loss: 0.2841\n",
            "Epoch 43/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2825 - val_loss: 0.2840\n",
            "Epoch 44/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2811 - val_loss: 0.2839\n",
            "Epoch 45/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2813 - val_loss: 0.2839\n",
            "Epoch 46/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2808 - val_loss: 0.2839\n",
            "Epoch 47/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2820 - val_loss: 0.2838\n",
            "Epoch 48/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2811 - val_loss: 0.2838\n",
            "Epoch 49/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2810 - val_loss: 0.2838\n",
            "Epoch 50/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2810 - val_loss: 0.2840\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep and Shallow Autoencoders using mnist\n"
      ],
      "metadata": {
        "id": "ypodGljTUEqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow keras numpy matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjBl0KhEVUKn",
        "outputId": "46d6df1f-df14-43b3-cd35-826b2a566823"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.12.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras import models\n",
        "from keras.layers import Input, Dense\n",
        "from keras.datasets import mnist\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data: flatten images and normalize\n",
        "x_train_flat = x_train.reshape((x_train.shape[0], -1)) / 255.0  # Shape: (60000, 784)\n",
        "x_test_flat = x_test.reshape((x_test.shape[0], -1)) / 255.0     # Shape: (10000, 784)\n",
        "\n",
        "# Build a deep autoencoder\n",
        "input_layer = Input(shape=(784,))\n",
        "encoded = Dense(128, activation='relu')(input_layer)\n",
        "encoded = Dense(64, activation='relu')(encoded)\n",
        "encoded = Dense(32, activation='relu')(encoded)\n",
        "decoded = Dense(64, activation='relu')(encoded)\n",
        "decoded = Dense(128, activation='relu')(decoded)\n",
        "decoded = Dense(784, activation='sigmoid')(decoded)\n",
        "deep_autoencoder = models.Model(inputs=input_layer, outputs=decoded)\n",
        "\n",
        "# Compile the deep autoencoder\n",
        "deep_autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the deep autoencoder\n",
        "deep_autoencoder.fit(x_train_flat, x_train_flat, epochs=50, batch_size=256, shuffle=True)\n",
        "\n",
        "# Create the encoder model for the deep autoencoder\n",
        "deep_encoder = models.Model(inputs=deep_autoencoder.input, outputs=deep_autoencoder.layers[2].output)\n",
        "\n",
        "# Extract features from the test set for the deep autoencoder\n",
        "deep_features = deep_encoder.predict(x_test_flat)\n",
        "\n",
        "# Check the shape of extracted features\n",
        "print(f\"Deep features shape: {deep_features.shape}\")  # Should be (10000, 32)\n",
        "\n",
        "# Train-test split for deep features\n",
        "X_train_deep, X_val_deep, y_train_deep, y_val_deep = train_test_split(deep_features, y_test, test_size=0.2, random_state=42)\n",
        "\n",
        "# Classifier for deep features\n",
        "classifier_deep = LogisticRegression(max_iter=1000)\n",
        "classifier_deep.fit(X_train_deep, y_train_deep)\n",
        "\n",
        "# Predictions and evaluation for deep features\n",
        "y_pred_deep = classifier_deep.predict(X_val_deep)\n",
        "print(\"Deep Autoencoder Classification Report:\")\n",
        "print(classification_report(y_val_deep, y_pred_deep))\n",
        "print(f\"Deep Autoencoder F1 Score: {f1_score(y_val_deep, y_pred_deep, average='weighted')}\")\n",
        "\n",
        "# Build a shallow autoencoder\n",
        "shallow_input_layer = Input(shape=(784,))\n",
        "shallow_encoded = Dense(64, activation='relu')(shallow_input_layer)\n",
        "shallow_decoded = Dense(784, activation='sigmoid')(shallow_encoded)\n",
        "shallow_autoencoder = models.Model(inputs=shallow_input_layer, outputs=shallow_decoded)\n",
        "\n",
        "# Compile the shallow autoencoder\n",
        "shallow_autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the shallow autoencoder\n",
        "shallow_autoencoder.fit(x_train_flat, x_train_flat, epochs=50, batch_size=256, shuffle=True)\n",
        "\n",
        "# Create the encoder model for the shallow autoencoder\n",
        "shallow_encoder = models.Model(inputs=shallow_autoencoder.input, outputs=shallow_autoencoder.layers[1].output)\n",
        "\n",
        "# Extract features from the test set for the shallow autoencoder\n",
        "shallow_features = shallow_encoder.predict(x_test_flat)\n",
        "\n",
        "# Check the shape of extracted features\n",
        "print(f\"Shallow features shape: {shallow_features.shape}\")  # Should be (10000, 64)\n",
        "\n",
        "# Train-test split for shallow features\n",
        "X_train_shallow, X_val_shallow, y_train_shallow, y_val_shallow = train_test_split(shallow_features, y_test, test_size=0.2, random_state=42)\n",
        "\n",
        "# Classifier for shallow features\n",
        "classifier_shallow = LogisticRegression(max_iter=1000)\n",
        "classifier_shallow.fit(X_train_shallow, y_train_shallow)\n",
        "\n",
        "# Predictions and evaluation for shallow features\n",
        "y_pred_shallow = classifier_shallow.predict(X_val_shallow)\n",
        "print(\"Shallow Autoencoder Classification Report:\")\n",
        "print(classification_report(y_val_shallow, y_pred_shallow))\n",
        "print(f\"Shallow Autoencoder F1 Score: {f1_score(y_val_shallow, y_pred_shallow, average='weighted')}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yDy1aw0V-j4",
        "outputId": "75269dd8-440e-476b-9909-d7e5a98c8d58"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0952\n",
            "Epoch 2/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0326\n",
            "Epoch 3/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0238\n",
            "Epoch 4/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0205\n",
            "Epoch 5/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0186\n",
            "Epoch 6/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0170\n",
            "Epoch 7/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0160\n",
            "Epoch 8/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0152\n",
            "Epoch 9/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0145\n",
            "Epoch 10/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0138\n",
            "Epoch 11/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0134\n",
            "Epoch 12/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0128\n",
            "Epoch 13/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0124\n",
            "Epoch 14/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0120\n",
            "Epoch 15/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0116\n",
            "Epoch 16/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0113\n",
            "Epoch 17/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0109\n",
            "Epoch 18/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0107\n",
            "Epoch 19/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0104\n",
            "Epoch 20/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0103\n",
            "Epoch 21/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0100\n",
            "Epoch 22/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0099\n",
            "Epoch 23/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0097\n",
            "Epoch 24/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0096\n",
            "Epoch 25/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0094\n",
            "Epoch 26/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0093\n",
            "Epoch 27/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0092\n",
            "Epoch 28/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0091\n",
            "Epoch 29/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0089\n",
            "Epoch 30/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0088\n",
            "Epoch 31/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0087\n",
            "Epoch 32/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0086\n",
            "Epoch 33/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0085\n",
            "Epoch 34/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0084\n",
            "Epoch 35/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0084\n",
            "Epoch 36/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0083\n",
            "Epoch 37/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0082\n",
            "Epoch 38/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0082\n",
            "Epoch 39/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0081\n",
            "Epoch 40/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0080\n",
            "Epoch 41/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0080\n",
            "Epoch 42/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0079\n",
            "Epoch 43/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0078\n",
            "Epoch 44/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0078\n",
            "Epoch 45/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0077\n",
            "Epoch 46/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0077\n",
            "Epoch 47/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0076\n",
            "Epoch 48/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0076\n",
            "Epoch 49/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0076\n",
            "Epoch 50/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0075\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Deep features shape: (10000, 64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deep Autoencoder Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97       203\n",
            "           1       0.96      0.96      0.96       216\n",
            "           2       0.88      0.92      0.90       213\n",
            "           3       0.92      0.91      0.91       208\n",
            "           4       0.93      0.87      0.90       215\n",
            "           5       0.85      0.87      0.86       174\n",
            "           6       0.93      0.93      0.93       200\n",
            "           7       0.90      0.93      0.91       187\n",
            "           8       0.93      0.87      0.90       186\n",
            "           9       0.88      0.89      0.89       198\n",
            "\n",
            "    accuracy                           0.91      2000\n",
            "   macro avg       0.91      0.91      0.91      2000\n",
            "weighted avg       0.91      0.91      0.91      2000\n",
            "\n",
            "Deep Autoencoder F1 Score: 0.9134532706781382\n",
            "Epoch 1/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0966\n",
            "Epoch 2/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0294\n",
            "Epoch 3/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0197\n",
            "Epoch 4/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0146\n",
            "Epoch 5/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115\n",
            "Epoch 6/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0092\n",
            "Epoch 7/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0075\n",
            "Epoch 8/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0065\n",
            "Epoch 9/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058\n",
            "Epoch 10/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0054\n",
            "Epoch 11/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051\n",
            "Epoch 12/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0049\n",
            "Epoch 13/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0047\n",
            "Epoch 14/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0046\n",
            "Epoch 15/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0045\n",
            "Epoch 16/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044\n",
            "Epoch 17/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0044\n",
            "Epoch 18/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0043\n",
            "Epoch 19/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043\n",
            "Epoch 20/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042\n",
            "Epoch 21/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0042\n",
            "Epoch 22/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0042\n",
            "Epoch 23/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0041\n",
            "Epoch 24/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0041\n",
            "Epoch 25/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0040\n",
            "Epoch 26/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0040\n",
            "Epoch 27/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0040\n",
            "Epoch 28/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0040\n",
            "Epoch 29/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0040\n",
            "Epoch 30/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0040\n",
            "Epoch 31/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0039\n",
            "Epoch 32/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0039\n",
            "Epoch 33/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0039\n",
            "Epoch 34/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0039\n",
            "Epoch 35/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0039\n",
            "Epoch 36/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0039\n",
            "Epoch 37/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0039\n",
            "Epoch 38/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0038\n",
            "Epoch 39/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0039\n",
            "Epoch 40/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0038\n",
            "Epoch 41/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0038\n",
            "Epoch 42/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0038\n",
            "Epoch 43/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0038\n",
            "Epoch 44/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0038\n",
            "Epoch 45/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0038\n",
            "Epoch 46/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0038\n",
            "Epoch 47/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0038\n",
            "Epoch 48/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0038\n",
            "Epoch 49/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0038\n",
            "Epoch 50/50\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0038\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "Shallow features shape: (10000, 64)\n",
            "Shallow Autoencoder Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.96      0.95       203\n",
            "           1       0.97      0.96      0.97       216\n",
            "           2       0.90      0.89      0.90       213\n",
            "           3       0.91      0.90      0.90       208\n",
            "           4       0.92      0.86      0.89       215\n",
            "           5       0.83      0.84      0.84       174\n",
            "           6       0.91      0.94      0.92       200\n",
            "           7       0.86      0.93      0.89       187\n",
            "           8       0.89      0.87      0.88       186\n",
            "           9       0.87      0.89      0.88       198\n",
            "\n",
            "    accuracy                           0.90      2000\n",
            "   macro avg       0.90      0.90      0.90      2000\n",
            "weighted avg       0.90      0.90      0.90      2000\n",
            "\n",
            "Shallow Autoencoder F1 Score: 0.9029835394965284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST 784 Variational Autoencoder (VAE)"
      ],
      "metadata": {
        "id": "qTHHAVqPRfet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Set up device (GPU/CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyperparameters\n",
        "latent_dim = 20\n",
        "batch_size = 128\n",
        "learning_rate = 1e-3\n",
        "epochs = 10\n",
        "\n",
        "# MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: x.view(-1))  # Flatten the image\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Variational Autoencoder model\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VAE, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 400)\n",
        "        self.fc21 = nn.Linear(400, latent_dim)  # mu layer\n",
        "        self.fc22 = nn.Linear(400, latent_dim)  # logvar layer\n",
        "        self.fc3 = nn.Linear(latent_dim, 400)\n",
        "        self.fc4 = nn.Linear(400, 784)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h1 = torch.relu(self.fc1(x))\n",
        "        return self.fc21(h1), self.fc22(h1)  # Return mean and log variance\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        h3 = torch.relu(self.fc3(z))\n",
        "        return torch.sigmoid(self.fc4(h3))  # Output in [0, 1]\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n",
        "\n",
        "# Loss function\n",
        "def loss_function(recon_x, x, mu, logvar):\n",
        "    BCE = nn.functional.binary_cross_entropy(recon_x, x, reduction='sum')\n",
        "    # KL divergence\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return BCE + KLD\n",
        "\n",
        "# Initialize the model, optimizer\n",
        "model = VAE().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, mu, logvar = model(data)\n",
        "        loss = loss_function(recon_batch, data, mu, logvar)\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
        "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item() / len(data):.6f}')\n",
        "    print(f'====> Epoch: {epoch} Average loss: {train_loss / len(train_loader.dataset):.4f}')\n",
        "\n",
        "# Testing\n",
        "def test(epoch):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (data, _) in enumerate(test_loader):\n",
        "            data = data.to(device)\n",
        "            recon_batch, mu, logvar = model(data)\n",
        "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print(f'====> Test set loss: {test_loss:.4f}')\n",
        "\n",
        "# Run training and testing\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train(epoch)\n",
        "    test(epoch)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3N53c-ARjEw",
        "outputId": "b1b51fa1-a61a-4b43-a35e-0e3d6c5edf76"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 546.712952\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 190.700165\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 155.847733\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 142.668930\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 135.765289\n",
            "====> Epoch: 1 Average loss: 164.2003\n",
            "====> Test set loss: 127.1140\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 128.097839\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 129.731049\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 121.028435\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 121.159935\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 120.471878\n",
            "====> Epoch: 2 Average loss: 121.0527\n",
            "====> Test set loss: 115.7938\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 113.664688\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 112.685486\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 112.139702\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 114.580826\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 115.815033\n",
            "====> Epoch: 3 Average loss: 114.2039\n",
            "====> Test set loss: 111.4041\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 113.962540\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 110.246513\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 109.743233\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 110.226410\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 113.368073\n",
            "====> Epoch: 4 Average loss: 111.3638\n",
            "====> Test set loss: 109.5222\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 111.484482\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 109.378418\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 110.404785\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 114.561127\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 110.632553\n",
            "====> Epoch: 5 Average loss: 109.7537\n",
            "====> Test set loss: 108.4163\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 109.092392\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 111.442169\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 106.607697\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 103.992928\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 107.536774\n",
            "====> Epoch: 6 Average loss: 108.5559\n",
            "====> Test set loss: 107.5274\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 107.899323\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 105.004890\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 107.113846\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 107.514969\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 103.189651\n",
            "====> Epoch: 7 Average loss: 107.7319\n",
            "====> Test set loss: 106.7994\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 103.416016\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 108.646683\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 111.261627\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 104.453484\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 107.645668\n",
            "====> Epoch: 8 Average loss: 107.1260\n",
            "====> Test set loss: 106.2170\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 107.362000\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 104.839317\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 111.175133\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 106.071823\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 108.362427\n",
            "====> Epoch: 9 Average loss: 106.6000\n",
            "====> Test set loss: 105.9637\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 104.543854\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 110.981308\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 106.986931\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 106.946167\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 102.944260\n",
            "====> Epoch: 10 Average loss: 106.1946\n",
            "====> Test set loss: 105.6023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KiPhGzbtSMV4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}